{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ei_8D2wEj5re",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nqbbp8CFwL_h"
      },
      "source": [
        "# Movie Review Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ky8sR9Fygoxb",
        "colab": {}
      },
      "source": [
        "def read_raw(file_name, label):\n",
        "  with open(file_name, 'r') as file:\n",
        "    data = []\n",
        "    for line in file:\n",
        "        processed_line = preprocess_raw(line)\n",
        "        data.append([processed_line.split(), label])\n",
        "  return data\n",
        "\n",
        "def preprocess_raw(text):\n",
        "  text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
        "  out = ''\n",
        "  for i, char in enumerate(text.lower()):\n",
        "    if char.isalpha()==True or char==' ':\n",
        "      out += char\n",
        "  out=\" \".join(out.split())\n",
        "  out += ' .'\n",
        "  return out\n",
        "\n",
        "def build_data(direc):\n",
        "  data=[]\n",
        "  counter=0\n",
        "  for label in ['pos', 'neg']:\n",
        "    label_direc = os.path.join(direc, label)\n",
        "    for filename in os.listdir(label_direc):\n",
        "      if (label == 'pos'):\n",
        "        data += read_raw(os.path.join(label_direc,str(filename)), 1)\n",
        "      else:\n",
        "        data += read_raw(os.path.join(label_direc,str(filename)), 0)\n",
        "      counter += 1\n",
        "      print(counter)\n",
        "  print('Done')\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cATbAuX8grnR",
        "colab": {}
      },
      "source": [
        "data = build_data('./drive/My Drive/txt_sentoken/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnYbLt0S5-vO",
        "colab_type": "text"
      },
      "source": [
        "# Data to File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xrAs4EG1DTcd",
        "colab": {}
      },
      "source": [
        "data = np.array(data)\n",
        "file = open('data', 'wb')\n",
        "pickle.dump(data, file)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coytsUvQ5-vU",
        "colab_type": "text"
      },
      "source": [
        "# Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q718-47w5-vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MovieReviewDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.data = dataset\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        temp = self.data[idx]\n",
        "        if (self.transform):\n",
        "            temp = self.transform(sample)\n",
        "        \n",
        "        sample = {'sentence': temp[0] ,'label': temp[1]}\n",
        "        return sample\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eV-J5by5-vY",
        "colab_type": "text"
      },
      "source": [
        "# Load data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7zJpLof5-vZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20fb29a4-91b5-421f-e5ac-298d3e81a83a"
      },
      "source": [
        "file = open('data', 'rb')\n",
        "data = pickle.load(file)\n",
        "file.close()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[:,0], data[:,1])\n",
        "dataset = []\n",
        "for i in range(len(X_train)):\n",
        "    dataset.append([X_train[i], y_train[i]])\n",
        "    \n",
        "mr = MovieReviewDataset(dataset)\n",
        "print(len(mr))\n",
        "\n",
        "\n",
        "mr_dataloader = DataLoader(mr, batch_size = 16, shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5FaxdBk5-vf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26bc8601-583c-4e00-b39a-ec9c9b3e7596"
      },
      "source": [
        "print(len(next(iter(mr_dataloader))['label']))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGBW_7bj5-vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRAN(nn.module):\n",
        "  def __init__(self,embedding_size,cnn_num_filters,cnn_window_length,LSTM_hidden_units,dropout_p):\n",
        "    super(CRAN,self).__init__()\n",
        "\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "      cnn_num_filters: the number of convolutional kernels, represents the number of output channels parameter in Conv2d\n",
        "      cnn_window_length: in a kernel size of d*l, d represents the embedding size and l represents the window length\n",
        "      LSTM_hidden_units: number of hidden units in LSTM layer\n",
        "      dropout: dropout probability for CNN\n",
        "      embedding_size: length of embedded word vectors \n",
        "    \"\"\"\n",
        "    self.cnn=torch.nn.Conv2d(1,cnn_num_filters,(cnn_window_length,embedding_size),stride=(1,0))\n",
        "    self.dropout=torch.nn.Dropout(p_dropout)\n",
        "    self.LSTM=torch.nn.LSTM(embedding_size,LSTM_hidden_units,1)\n",
        "  def forward(self,batch,labels):\n",
        "    (N,T,d)=batch.shape\n",
        "    #apply convolutional filters to the input sentences\n",
        "    cnn_output=self.cnn(batch)\n",
        "    #cnn_output will be of shape (N,cnn_num_filters,H_out from Pytorch documentation,1)\n",
        "    shape=cnn_output.shape\n",
        "    cnn_output=cnn_output.view(N,shape[1],shape[2])\n",
        "    #average across the different filter outputs\n",
        "    cnn_output=torch.mean(cnn_output,1)\n",
        "    batch_for_LSTM=batch.permute(1,0,2)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OlBnDufnFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "54ed17db-9d00-426b-e5d8-11dbc16d2d3b"
      },
      "source": [
        "a=torch.randn(2,4,4)\n",
        "print(a)\n",
        "print(torch.mean(a,1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.2665,  0.3923, -1.1571,  1.8619],\n",
            "         [-0.1448,  0.0378, -0.5983,  1.1201],\n",
            "         [ 0.2034,  0.9530,  1.3362, -0.9622],\n",
            "         [-1.5275, -0.8303, -0.4121,  0.0396]],\n",
            "\n",
            "        [[-0.6037,  0.1255,  1.1212, -0.4120],\n",
            "         [ 0.5883,  0.6299,  2.3593, -1.4743],\n",
            "         [-1.0952,  1.0461, -2.1049, -1.2259],\n",
            "         [ 1.6651,  1.6533, -0.2928,  3.5429]]])\n",
            "tensor([[-0.6838,  0.1382, -0.2078,  0.5148],\n",
            "        [ 0.1386,  0.8637,  0.2707,  0.1077]])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}