{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei_8D2wEj5re"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nqbbp8CFwL_h"
   },
   "source": [
    "# Movie Review Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ky8sR9Fygoxb"
   },
   "outputs": [],
   "source": [
    "def read_raw(file_name, label):\n",
    "  with open(file_name, 'r') as file:\n",
    "    data = []\n",
    "    for line in file:\n",
    "        processed_line = preprocess_raw(line)\n",
    "        data.append([processed_line.split(), label])\n",
    "  return data\n",
    "\n",
    "def preprocess_raw(text):\n",
    "  text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "  out = ''\n",
    "  for i, char in enumerate(text.lower()):\n",
    "    if char.isalpha()==True or char==' ':\n",
    "      out += char\n",
    "  out=\" \".join(out.split())\n",
    "  return out\n",
    "\n",
    "def build_data(direc):\n",
    "  data=[]\n",
    "  counter=0\n",
    "  for label in ['pos', 'neg']:\n",
    "    label_direc = os.path.join(direc, label)\n",
    "    for filename in os.listdir(label_direc):\n",
    "      if (label == 'pos'):\n",
    "        data += read_raw(os.path.join(label_direc,str(filename)), 1)\n",
    "      else:\n",
    "        data += read_raw(os.path.join(label_direc,str(filename)), 0)\n",
    "      counter += 1\n",
    "  print('Done')\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cATbAuX8grnR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "data = build_data('./txt_sentoken/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnYbLt0S5-vO"
   },
   "source": [
    "# Data to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrAs4EG1DTcd"
   },
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "file = open('data', 'wb')\n",
    "pickle.dump(data, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "coytsUvQ5-vU"
   },
   "source": [
    "# Movie Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q718-47w5-vV"
   },
   "outputs": [],
   "source": [
    "class MovieReviewDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.data = dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        temp = self.data[idx]\n",
    "        if (self.transform):\n",
    "            temp = self.transform(sample)\n",
    "        \n",
    "        sample = {'sentence': temp[0] ,'label': temp[1]}\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8eV-J5by5-vY"
   },
   "source": [
    "# Load data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A7zJpLof5-vZ",
    "outputId": "aa58d6d9-bdd1-4080-8405-244d69f18aec"
   },
   "outputs": [],
   "source": [
    "file = open('data', 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hucr8u6uievD"
   },
   "outputs": [],
   "source": [
    "embed_model = Word2Vec(size=300, min_count=1)\n",
    "embed_model.build_vocab(data[:,0])\n",
    "total_examples = embed_model.corpus_count\n",
    "pretrained = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "embed_model.build_vocab([list(pretrained.vocab.keys())], update=True)\n",
    "embed_model.intersect_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True, lockf=1.0)\n",
    "embed_model.train(data[:,0], total_examples=total_examples, epochs=embed_model.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_haw40hievH"
   },
   "outputs": [],
   "source": [
    "embed_model.wv.save('embedding_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures to determine max_freq and sentence length cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "oqRcR9SJLjHT",
    "outputId": "9783ff42-a2b3-46b2-cc44-35782f7eef5a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text=data[:,0]\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def len_dis(text):\n",
    "  lens = [len(line) for line in text]\n",
    "  len_counter = collections.Counter(lens)\n",
    "\n",
    "  lens = np.array(list(len_counter.keys()))\n",
    "  sort_idx = np.argsort(lens)\n",
    "  lens_sort = lens[sort_idx]\n",
    "  len_counts = np.array(list(len_counter.values()))\n",
    "  len_counts_sort = len_counts[sort_idx]\n",
    "  p = np.cumsum(len_counts_sort) / len_counts_sort.sum()\n",
    "  return p, lens_sort\n",
    "  \n",
    "src_p, src_lens_sort = len_dis(text)\n",
    "plt.plot(src_lens_sort, src_p, 'r-', label='eng')\n",
    "plt.title('Cumulative Distribution of Sentence Length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "F7yfDZjVLox2",
    "outputId": "4d71c437-eb25-46b7-ddf6-51d004d168d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def len_dis(text):\n",
    "  words = [token for line in text for token in line]\n",
    "  word_counter = collections.Counter(words)\n",
    "  freq_counter=  collections.Counter(word_counter.values())\n",
    "  freqs = np.array(list(freq_counter.keys()))\n",
    "  freq_length = np.array(list(freq_counter.values()))\n",
    "  sort_idx= np.argsort(freqs)\n",
    "  freq_sort = freqs[sort_idx]\n",
    "  freq_length = np.array(list(freq_counter.values()))\n",
    "  freq_length_sort = freq_length[sort_idx]\n",
    "  p = np.cumsum(freq_length_sort) / freq_length_sort.sum()\n",
    "  return p, freq_sort\n",
    "  \n",
    "src_p, src_lens_sort = len_dis(text)\n",
    "plt.plot(src_lens_sort, src_p, 'r-', label='eng')\n",
    "plt.title('Cumulative Distribution of Word Occurence')\n",
    "plt.legend()\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([1,100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrKjnRgQkTMk"
   },
   "outputs": [],
   "source": [
    "MIN_FREQ=30\n",
    "MAX_LEN=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container class for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Njv_eA9ZievS"
   },
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "  def __init__(self, name, tokens, min_freq):\n",
    "    self.name = name\n",
    "    self.index2word = {\n",
    "      0: 'pad',\n",
    "      1: 'unk'\n",
    "    }\n",
    "    self.word2index = {v: k for k, v in self.index2word.items()}\n",
    "    self.num_word = 2\n",
    "    token_freq = collections.Counter(tokens)\n",
    "    tokens = [token for token in tokens if token_freq[token] >= MIN_FREQ]\n",
    "    self._build_vocab(tokens)\n",
    "    \n",
    "  def _build_vocab(self, tokens):\n",
    "    for token in tokens:\n",
    "      if token not in self.word2index:\n",
    "        self.word2index[token] = self.num_word\n",
    "        self.index2word[self.num_word] = token\n",
    "        self.num_word += 1\n",
    "        \n",
    "  def __getitem__(self, tokens):\n",
    "    if not isinstance(tokens, (list, tuple)):\n",
    "      return self.word2index.get(tokens, self.word2index['unk'])\n",
    "    else:\n",
    "      return [self.__getitem__(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkgiV8PYnwUx"
   },
   "outputs": [],
   "source": [
    "def build_vocab(name, tokens, min_freq):\n",
    "  sentences=tokens[:,0]\n",
    "  tokens = [token for sentence in sentences for token in sentence]\n",
    "  return Vocab(name, tokens, min_freq)\n",
    "\n",
    "def build_vocabs(lang_src, src_text):\n",
    "  vocab_src = build_vocab(lang_src, src_text, MIN_FREQ)\n",
    "  return vocab_src\n",
    "\n",
    "def pad(line, padding_token):\n",
    "  return line + [padding_token] * (MAX_LEN-len(line))\n",
    "\n",
    "def build_tensor(text, reviews_vocab):\n",
    "  labels=text[:,1]\n",
    "  lines = [reviews_vocab[line] for line in text[:,0]]\n",
    "  lst=[]\n",
    "  for i in range(len(lines)):\n",
    "    padded_sentence=torch.tensor(pad(lines[i],reviews_vocab['pad']))\n",
    "    label=torch.tensor(labels[i])\n",
    "    lst.append([padded_sentence,label])\n",
    "  return lst\n",
    "\n",
    "def load_reviews_data():\n",
    "  reviews_vocab = build_vocabs('reviews', data)\n",
    "  for i in range(len(data[:,0])):\n",
    "    data[:,0][i]=data[:,0][i][:MAX_LEN]\n",
    "  reviews_array = build_tensor(data, reviews_vocab)\n",
    "  return reviews_vocab,reviews_array\n",
    "\n",
    "\n",
    "#source, target = prepare_data(raw_text, max_len=MAX_LEN)\n",
    "#vocab_eng, vocab_fra, train_iter = load_data_nmt(batch_size=2)\n",
    "#print('Vocabulary size of source language: {}'.format(vocab_eng.num_word))\n",
    "#print('Vocabulary size of target language: {}'.format(vocab_fra.num_word))\n",
    "#print('Total number of sentence pairs: {}'.format(len(source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wknd8TGe3OS2"
   },
   "outputs": [],
   "source": [
    "reviews_vocab,reviews_array=load_reviews_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAN used with Pytorch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BN4NHZ9eNzfr"
   },
   "outputs": [],
   "source": [
    "class CRAN(nn.Module):\n",
    "  def __init__(self,vocab_size,embedding_size,cnn_window_length,hidden_units,p_dropout):\n",
    "    super(CRAN, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      cnn_num_filters: the number of convolutional kernels, represents the number of output channels parameter in Conv2d\n",
    "      cnn_window_length: in a kernel size of d*l, d represents the embedding size and l represents the window length\n",
    "      LSTM_hidden_units: number of hidden units in LSTM layer\n",
    "      dropout: dropout probability for CNN\n",
    "      embedding_size: length of embedded word vectors \n",
    "    \"\"\"\n",
    "    self.embedding=nn.Embedding(vocab_size,embedding_size)\n",
    "    self.cnn=torch.nn.Conv2d(1,hidden_units,(cnn_window_length,embedding_size), padding=(1,0))\n",
    "    self.dropout=torch.nn.Dropout(p_dropout)\n",
    "    self.rnn=torch.nn.LSTM(embedding_size,hidden_units,1, batch_first=True)\n",
    "    self.hidden_size = hidden_units\n",
    "    self.dense = nn.Linear(hidden_units, 2)\n",
    "  def forward(self,batch,labels):\n",
    "    word_embedded=self.embedding(batch)\n",
    "    (N,T,d)=word_embedded.shape\n",
    "    word_embedded=word_embedded.view(N,1,T,d)\n",
    "    #apply convolutional filters to the input sentences\n",
    "    cnn_output=self.cnn(word_embedded)\n",
    "    #cnn_output will be of shape (N,cnn_num_filters,H_out from Pytorch documentation,1)\n",
    "    shape=cnn_output.shape\n",
    "    cnn_output= F.relu(cnn_output.view(N,shape[1],shape[2]))\n",
    "    #average across the different filter outputs\n",
    "    cnn_output=torch.mean(cnn_output,1)\n",
    "    h = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "    c = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "    word_embedded=word_embedded.view(N,T,d)\n",
    "  \n",
    "    lstm_out, (h,c) = self.rnn(word_embedded, (h, c))\n",
    "\n",
    "    s = torch.mean(lstm_out * cnn_output.unsqueeze(2), 1)\n",
    "\n",
    "    pred = F.log_softmax(self.dense(s))\n",
    "    \n",
    "    if self.training:\n",
    "      loss = F.nll_loss(pred, labels)\n",
    "\n",
    "      return loss, pred.argmax(dim=-1)\n",
    "    else:\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training CRAN with Pytorch embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nq7hfnE_PjLf",
    "outputId": "0c7822fa-2633-45ae-c3b1-c47ba436b6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cef542745214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reviews=torch.zeros((len(reviews_array),len(reviews_array[0][0])),dtype=torch.long)\n",
    "labels=torch.zeros((len(reviews_array)),dtype=torch.long)\n",
    "for i in range(len(reviews_array)):\n",
    "  reviews[i]=torch.tensor(reviews_array[i][0])\n",
    "  labels[i]=torch.tensor(reviews_array[i][1])\n",
    "\n",
    "batch_size = 16\n",
    "vocab_size=reviews_vocab.num_word\n",
    "embedding_dim = 100\n",
    "hidden_size = 100\n",
    "cnn_window_length=3\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "p_dropout=0.5\n",
    "\n",
    "CRAN_m = CRAN(vocab_size, embedding_dim, cnn_window_length,hidden_size,p_dropout)\n",
    "device = torch.device('cuda:0') # cuda:0 if you have gpu\n",
    "CRAN_m = CRAN_m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(CRAN_m.parameters(), lr=lr)\n",
    "loss_list = []\n",
    "for e in range(epoch):\n",
    "  CRAN_m.train()\n",
    "  permutation=torch.randperm(reviews.size()[0])\n",
    "  for i in range(0,reviews.size()[0],batch_size):\n",
    "    indices = permutation[i:i+batch_size]\n",
    "    reviews_batch, labels_batch = reviews[indices], labels[indices]\n",
    "    reviews_batch=reviews_batch.to(device)\n",
    "    labels_batch=labels_batch.to(device)\n",
    "    loss, pred = CRAN_m(reviews_batch,labels_batch)\n",
    "    loss_list.append(loss.mean().detach())\n",
    "    optimizer.zero_grad()\n",
    "    loss.mean().backward()\n",
    "    optimizer.step()\n",
    "    if i%5000==0:\n",
    "      print(loss.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDOtN_X9nhcK"
   },
   "outputs": [],
   "source": [
    "class GoogleEmbedding(nn.Module):\n",
    "  def __init__(self, model_path):\n",
    "    super(GoogleEmbedding, self).__init__()\n",
    "\n",
    "    # Load Google's pre-trained Word2Vec model.\n",
    "    self.model = KeyedVectors.load(model_path, mmap='r')\n",
    "\n",
    "  def forward(self, batch):\n",
    "    out = []\n",
    "    for sent in batch:\n",
    "      sent_embed = []\n",
    "      for word in sent:\n",
    "        sent_embed.append(self.model[word])\n",
    "      \n",
    "      sent_embed = np.array(sent_embed)\n",
    "      out.append(sent_embed)\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "qvaMIEUtnv5M",
    "outputId": "01bd00f1-27b1-4614-a8d7-0765fef70759"
   },
   "outputs": [],
   "source": [
    "embedding = GoogleEmbedding('embedding_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA6fHmgwFjsp"
   },
   "outputs": [],
   "source": [
    "# removing empty sentences\n",
    "del_lst=[]\n",
    "for i in range(len(data)):\n",
    "    if len(data[:,0][i])==0:\n",
    "        del_lst.append(i)\n",
    "data=np.delete(data,del_lst,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIb_X-h_Fjss"
   },
   "outputs": [],
   "source": [
    "# limit sentence length\n",
    "for i in range(len(data)):\n",
    "    data[:,0][i]=data[:,0][i][:MAX_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded Movie Review dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I45ic94onxgu"
   },
   "outputs": [],
   "source": [
    "reviews_array=embedding(data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsHt-og4Fjsx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reviews_array)):\n",
    "    if (i % 1000 == 0):\n",
    "        print(i)\n",
    "    avg_vector=np.reshape(np.repeat(np.reshape(np.average(reviews_array[i],axis=0),(1,300)),MAX_LEN-len(reviews_array[i]),axis=0),(MAX_LEN-len(reviews_array[i]),300))\n",
    "    reviews_array[i]=np.concatenate((reviews_array[i],avg_vector),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAN with Google embedding attention random init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiPaZiieFjs4"
   },
   "outputs": [],
   "source": [
    "#CRAN used with word2vec embedding\n",
    "class CRANword2vec(nn.Module):\n",
    "  def __init__(self,embedding_size,cnn_window_length,hidden_units,p_dropout):\n",
    "    super(CRANword2vec, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      cnn_num_filters: the number of convolutional kernels, represents the number of output channels parameter in Conv2d\n",
    "      cnn_window_length: in a kernel size of d*l, d represents the embedding size and l represents the window length\n",
    "      LSTM_hidden_units: number of hidden units in LSTM layer\n",
    "      dropout: dropout probability for CNN\n",
    "      embedding_size: length of embedded word vectors \n",
    "    \"\"\"\n",
    "    self.cnn=torch.nn.Conv2d(1,hidden_units,(cnn_window_length,embedding_size), padding=(1,0))\n",
    "    self.dropout=torch.nn.Dropout(p_dropout)\n",
    "    self.rnn=torch.nn.LSTM(embedding_size,hidden_units,1, batch_first=True)\n",
    "    self.hidden_size = hidden_units\n",
    "    self.dense = nn.Linear(hidden_units, 2)\n",
    "  def forward(self,batch,labels):\n",
    "    (N,T,d)=batch.shape\n",
    "    batch=batch.view(N,1,T,d)\n",
    "    #apply convolutional filters to the input sentences\n",
    "    cnn_output=self.cnn(batch)\n",
    "    #cnn_output will be of shape (N,cnn_num_filters,H_out from Pytorch documentation,1)\n",
    "    shape=cnn_output.shape\n",
    "    cnn_output= F.relu(cnn_output.view(N,shape[1],shape[2]))\n",
    "    #average across the different filter outputs\n",
    "    cnn_output=torch.mean(cnn_output,1)\n",
    "    h = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "    c = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "    batch=batch.view(N,T,d)\n",
    "  \n",
    "    lstm_out, (h,c) = self.rnn(batch, (h, c))\n",
    "\n",
    "    s = torch.mean(lstm_out * cnn_output.unsqueeze(2), 1)\n",
    "\n",
    "    pred = F.log_softmax(self.dense(s))\n",
    "    \n",
    "    if self.training:\n",
    "      loss = F.nll_loss(pred, labels)\n",
    "\n",
    "      return loss, pred.argmax(dim=-1)\n",
    "    else:\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training CRAN with word2vec embedding\n",
    "reviews=torch.zeros((len(reviews_array),reviews_array[0].shape[0],reviews_array[0].shape[1])).float()\n",
    "labels=torch.zeros((len(reviews_array)),dtype=torch.long)\n",
    "for i in range(len(reviews_array)):\n",
    "    reviews[i]=torch.tensor(reviews_array[i])\n",
    "    labels[i]=torch.tensor(data[:,1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CRAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8S_iNwXjFjs6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\noptimizer = torch.optim.Adadelta(CRAN_m.parameters(), lr=lr)\\nloss_list = []\\nfor e in range(epoch):\\n    CRAN_m.train()\\n    permutation=torch.randperm(reviews.size()[0])\\n    for i in range(0,reviews.size()[0],batch_size):\\n        indices = permutation[i:i+batch_size]\\n        reviews_batch, labels_batch = reviews[indices], labels[indices]\\n        reviews_batch=reviews_batch.to(device)\\n        labels_batch=labels_batch.to(device)\\n        loss, pred = CRAN_m(reviews_batch,labels_batch)\\n        loss_list.append(loss.mean().detach())\\n        optimizer.zero_grad()\\n        loss.mean().backward()\\n        optimizer.step()\\n        if i%5000==0:\\n          print('Loss: '+str(loss.mean()))\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "vocab_size=reviews_vocab.num_word\n",
    "embedding_dim = 300\n",
    "hidden_size = 100\n",
    "cnn_window_length=3\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "p_dropout=0.5\n",
    "\n",
    "CRAN_m = CRANword2vec(embedding_dim, cnn_window_length,hidden_size,p_dropout)\n",
    "device = torch.device('cuda:0') # cuda:0 if you have gpu\n",
    "CRAN_m = CRAN_m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adadelta(CRAN_m.parameters(), lr=lr)\n",
    "loss_list = []\n",
    "for e in range(epoch):\n",
    "    CRAN_m.train()\n",
    "    permutation=torch.randperm(reviews.size()[0])\n",
    "    for i in range(0,reviews.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        reviews_batch, labels_batch = reviews[indices], labels[indices]\n",
    "        reviews_batch=reviews_batch.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        loss, pred = CRAN_m(reviews_batch,labels_batch)\n",
    "        loss_list.append(loss.mean().detach())\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        if i%5000==0:\n",
    "          print('Loss: '+str(loss.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN (CRAN without LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRAN used with word2vec embedding\n",
    "class CAN(nn.Module):\n",
    "  def __init__(self,embedding_size,cnn_window_length,hidden_units,p_dropout):\n",
    "    super(CAN, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      cnn_num_filters: the number of convolutional kernels, represents the number of output channels parameter in Conv2d\n",
    "      cnn_window_length: in a kernel size of d*l, d represents the embedding size and l represents the window length\n",
    "      LSTM_hidden_units: number of hidden units in LSTM layer\n",
    "      dropout: dropout probability for CNN\n",
    "      embedding_size: length of embedded word vectors \n",
    "    \"\"\"\n",
    "    self.cnn=torch.nn.Conv2d(1,hidden_units,(cnn_window_length,embedding_size), padding=(1,0))\n",
    "    self.dropout=torch.nn.Dropout(p_dropout)\n",
    "    self.hidden_size = hidden_units\n",
    "    self.dense = nn.Linear(hidden_units*MAX_LEN, 2)\n",
    "  def forward(self,batch,labels):\n",
    "    (N,T,d)=batch.shape\n",
    "    #apply convolutional filters to the input sentences\n",
    "    cnn_output=self.cnn(batch.view(N,1,T,d))\n",
    "    #cnn_output will be of shape (N,cnn_num_filters,H_out from Pytorch documentation,1)\n",
    "    shape=cnn_output.shape\n",
    "    cnn_output= F.relu(cnn_output.squeeze(3))\n",
    "\n",
    "    s = cnn_output.view(N, -1)\n",
    "\n",
    "    pred = F.log_softmax(self.dense(s))\n",
    "    \n",
    "    if self.training:\n",
    "      loss = F.nll_loss(pred, labels)\n",
    "\n",
    "      return loss, pred.argmax(dim=-1)\n",
    "    else:\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidmu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.9689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.4530, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "vocab_size=reviews_vocab.num_word\n",
    "embedding_dim = 300\n",
    "hidden_size = 100\n",
    "cnn_window_length=3\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "p_dropout=0.5\n",
    "\n",
    "CAN_m = CAN(embedding_dim, cnn_window_length,hidden_size,p_dropout)\n",
    "device = torch.device('cuda:0') # cuda:0 if you have gpu\n",
    "CAN_m = CAN_m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(CAN_m.parameters(), lr=lr)\n",
    "loss_list = []\n",
    "for e in range(epoch):\n",
    "    CRAN_m.train()\n",
    "    permutation=torch.randperm(reviews.size()[0])\n",
    "    for i in range(0,reviews.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        reviews_batch, labels_batch = reviews[indices], labels[indices]\n",
    "        reviews_batch=reviews_batch.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        loss, pred = CAN_m(reviews_batch,labels_batch)\n",
    "        loss_list.append(loss.mean().detach())\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        if i%5000==0:\n",
    "          print('Loss: '+str(loss.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CAN Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidmu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "CAN_m.eval()\n",
    "permutation=torch.randperm(reviews.size()[0])\n",
    "indices = permutation[i:i+batch_size]\n",
    "reviews_batch, labels_batch = reviews[indices], labels[indices]\n",
    "reviews_batch=reviews_batch.to(device)\n",
    "labels_batch=labels_batch.to(device)\n",
    "pred = CAN_m(reviews_batch,labels_batch)\n",
    "print(accuracy_score(labels_batch.cpu(),pred.argmax(dim=-1).cpu()))\n",
    "\n",
    "# Get pretrained params\n",
    "CAN_named_params = CAN_m.state_dict()\n",
    "pretrained_CAN_weights = CAN_named_params['cnn.weight'].cpu()\n",
    "pretrained_CAN_bias = CAN_named_params['cnn.bias'].cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRAN with Google embedding attention pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRAN used with word2vec embedding\n",
    "class PtCRANword2vec(nn.Module):\n",
    "  def __init__(self,embedding_size,cnn_window_length,hidden_units,p_dropout):\n",
    "    super(PtCRANword2vec, self).__init__()\n",
    "\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      cnn_num_filters: the number of convolutional kernels, represents the number of output channels parameter in Conv2d\n",
    "      cnn_window_length: in a kernel size of d*l, d represents the embedding size and l represents the window length\n",
    "      LSTM_hidden_units: number of hidden units in LSTM layer\n",
    "      dropout: dropout probability for CNN\n",
    "      embedding_size: length of embedded word vectors \n",
    "    \"\"\"\n",
    "    self.cnn=torch.nn.Conv2d(1,hidden_units,(cnn_window_length,embedding_size), padding=(1,0))\n",
    "    \n",
    "    # init cnn params to pretrained\n",
    "    self.cnn.weight.data = pretrained_CAN_weights\n",
    "    self.cnn.bias.data = pretrained_CAN_bias\n",
    "    \n",
    "    \n",
    "    self.dropout=torch.nn.Dropout(p_dropout)\n",
    "    self.rnn=torch.nn.LSTM(embedding_size,hidden_units,1, batch_first=True)\n",
    "    self.hidden_size = hidden_units\n",
    "    self.dense = nn.Linear(hidden_units, 2)\n",
    "  def forward(self,batch,labels):\n",
    "    (N,T,d)=batch.shape\n",
    "    #apply convolutional filters to the input sentences\n",
    "    cnn_output=self.cnn(batch.view(N,1,T,d))\n",
    "    #cnn_output will be of shape (N,cnn_num_filters,H_out from Pytorch documentation,1)\n",
    "    shape=cnn_output.shape\n",
    "    cnn_output= F.relu(cnn_output.squeeze(3))\n",
    "    #average across the different filter outputs\n",
    "    cnn_output=torch.mean(cnn_output,1)\n",
    "    h = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "    c = batch.new_zeros(1, N, self.hidden_size).float()\n",
    "  \n",
    "    lstm_out, (h,c) = self.rnn(batch, (h, c))\n",
    "\n",
    "    s = torch.mean(lstm_out * cnn_output.unsqueeze(2), 1)\n",
    "\n",
    "    pred = F.log_softmax(self.dense(s))\n",
    "    \n",
    "    if self.training:\n",
    "      loss = F.nll_loss(pred, labels)\n",
    "\n",
    "      return loss, pred.argmax(dim=-1)\n",
    "    else:\n",
    "      return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sidmu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-9b69e211db65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mreviews_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mreviews_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreviews_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mlabels_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCRAN_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "vocab_size=reviews_vocab.num_word\n",
    "embedding_dim = 300\n",
    "hidden_size = 100\n",
    "cnn_window_length=3\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "p_dropout=0.5\n",
    "\n",
    "CRAN_m = PtCRANword2vec(embedding_dim, cnn_window_length,hidden_size,p_dropout)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda:0 if you have gpu\n",
    "CRAN_m = CRAN_m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adadelta(CRAN_m.parameters(), lr=lr)\n",
    "loss_list = []\n",
    "for e in range(epoch):\n",
    "    CRAN_m.train()\n",
    "    permutation=torch.randperm(reviews.size()[0])\n",
    "    for i in range(0,reviews.size()[0],batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        reviews_batch, labels_batch = reviews[indices], labels[indices]\n",
    "        reviews_batch=reviews_batch.to(device)\n",
    "        labels_batch=labels_batch.to(device)\n",
    "        loss, pred = CRAN_m(reviews_batch,labels_batch)\n",
    "        loss_list.append(loss.mean().detach())\n",
    "        optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        optimizer.step()\n",
    "        if i%5000==0:\n",
    "          print('Loss: '+str(loss.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CRAN_New.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bit5f1e063edef4426a9023218e27969b44"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
